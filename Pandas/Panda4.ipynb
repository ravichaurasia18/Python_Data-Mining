{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Panda4.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPI1kHlw5puiE0ekB+bTXvP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravichaurasia18/Python_Data-Mining/blob/master/Pandas/Panda4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05sUHgMEKBt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "myFile = files.upload()\n",
        "myFile2 = files.upload()\n",
        "myFiles3 = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLP0sGbELNhQ",
        "colab_type": "text"
      },
      "source": [
        "Another example to read Dirrect\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "market_df = pd.read_csv(\"C:\\\\Users\\\\SUMITH\\\\Python Notebooks\\\\Python Notebooks\\\\upGrad College Program\\\\Pandas\\\\global_sales_data/market_fact.csv\")\n",
        "customer_df = pd.read_csv(\"C:\\\\Users\\\\SUMITH\\\\Python Notebooks\\\\Python Notebooks\\\\upGrad College Program\\\\Pandas\\\\global_sales_data/cust_dimen.csv\")\n",
        "product_df = pd.read_csv(\"C:\\\\Users\\\\SUMITH\\\\Python Notebooks\\\\Python Notebooks\\\\upGrad College Program\\\\Pandas\\\\global_sales_data/prod_dimen.csv\")\n",
        "shipping_df = pd.read_csv(\"C:\\\\Users\\\\SUMITH\\\\Python Notebooks\\\\Python Notebooks\\\\upGrad College Program\\\\Pandas\\\\global_sales_data/shipping_dimen.csv\")\n",
        "orders_df = pd.read_csv(\"C:\\\\Users\\\\SUMITH\\\\Python Notebooks\\\\Python Notebooks\\\\upGrad College Program\\\\Pandas\\\\global_sales_data/orders_dimen.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhZu3BtAKwc6",
        "colab_type": "text"
      },
      "source": [
        "here we merge and Concation of multiple of data set Now It Syntax\n",
        "1 : help(pd.merge)\n",
        "2: # Merging the dataframes\n",
        "   # Note that Cust_id is the common column/key, which is provided to the 'on' argument\n",
        "# how = 'inner' makes sure that only the customer ids present in both dfs are included in the result\n",
        "df_1 = pd.merge(market_df, customer_df, how='inner', on='Cust_id')\n",
        "df_1.head()\n",
        "3 : # Now, you can subset the orders made by customers from 'Corporate' segment\n",
        "df_1.loc[df_1['Customer_Segment'] == 'CORPORATE', :]\n",
        "4 : # Example 2: Select all orders from product category = office supplies and from the corporate segment\n",
        "# We now need to merge the product_df\n",
        "\n",
        "df_2 = pd.merge(df_1, product_df, how='inner', on='Prod_id')\n",
        "df_2.head()\n",
        "5 : # Select all orders from product category = office supplies and from the corporate segment\n",
        "df_2.loc[(df_2['Product_Category']=='OFFICE SUPPLIES') & (df_2['Customer_Segment']=='CORPORATE'),:]\n",
        "6 : # Merging shipping_df\n",
        "df_3 = pd.merge(df_2, shipping_df, how='inner', on='Ship_id')\n",
        "df_3.shape\n",
        "7 :# Merging the orders table to create a master df\n",
        "master_df = pd.merge(df_3, orders_df, how='inner', on='Ord_id')\n",
        "master_df.shape\n",
        "master_df.head()\n",
        "8 : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAOlNotgL5l5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataframes having the same columns\n",
        "import pandas as pd\n",
        "df1 = pd.DataFrame({'Name': ['Aman', 'Joy', 'Rashmi', 'Saif'],\n",
        "                    'Age': ['34', '31', '22', '33'],\n",
        "                    'Gender': ['M', 'M', 'F', 'M']}\n",
        "                  )\n",
        "\n",
        "df2 = pd.DataFrame({'Name': ['Akhil', 'Asha', 'Preeti'],\n",
        "                    'Age': ['31', '22', '23'],\n",
        "                    'Gender': ['M', 'F', 'F']}\n",
        "                  )\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qanI_uerMYvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30YAdjZ8Mds8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To concatenate them, one on top of the other, you can use pd.concat\n",
        "# The first argument is a sequence (list) of dataframes\n",
        "# axis = 0 indicates that we want to concat along the row axis\n",
        "pd.concat([df1, df2], axis = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq3OlooLMmp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A useful and intuitive alternative to concat along the rows is the append() function\n",
        "# It concatenates along the rows\n",
        "df1.append(df2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqyCmanuMsyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = pd.DataFrame({'Name': ['Aman', 'Joy', 'Rashmi', 'Saif'],\n",
        "                    'Age': ['34', '31', '22', '33'],\n",
        "                    'Gender': ['M', 'M', 'F', 'M']}\n",
        "                  )\n",
        "df1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwf20KmcMy8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2 = pd.DataFrame({'School': ['RK Public', 'JSP', 'Carmel Convent', 'St. Paul'],\n",
        "                    'Graduation Marks': ['84', '89', '76', '91']}\n",
        "                  )\n",
        "df2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsUGymV1M9hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To join the two dataframes, use axis = 1 to indicate joining along the columns axis\n",
        "# The join is possible because the corresponding rows have the same indices\n",
        "pd.concat([df1, df2], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g9ioMZHNJOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1.append(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruIhs4DLNbkx",
        "colab_type": "text"
      },
      "source": [
        "Pandas Chapter 6 : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCteLK1uNn4a",
        "colab_type": "text"
      },
      "source": [
        "Grouping And Summarising\n",
        "\n",
        "\n",
        "Grouping and aggregation are some of the most frequently used operations in data analysis, especially while doing exploratory data analysis (EDA), where comparing summary statistics across groups of data is common.\n",
        "\n",
        "For e.g., in the retail sales data we are working with, you may want to compare the average sales of various regions, or compare the total profit of two customer segments.\n",
        "\n",
        "Grouping analysis can be thought of as having three parts:\n",
        "\n",
        "Splitting the data into groups (e.g. groups of customer segments, product categories, etc.)\n",
        "Applying a function to each group (e.g. mean or total sales of each customer segment)\n",
        "Combining the results into a data structure showing the summary statistics\n",
        "Let's work through some examples.\n",
        "\n",
        "Unsupported Cell Type. Double-Click to inspect/edit the content.\n",
        "Unsupported Cell Type. Double-Click to inspect/edit the content.\n",
        "\n",
        "Say you want to understand how well or poorly the business is doing in various customer segments, regions, product categories etc. Specifically, you want to identify areas of business where you are incurrring heavy losses, and want to take action accordingly.\n",
        "\n",
        "To do that, we will answer questions such as:\n",
        "\n",
        "Which customer segments are the least profitable?\n",
        "Which product categories and sub-categories are the least profitable?\n",
        "Customers in which geographic region cause the most losses?\n",
        "Etc.\n",
        "First, we will merge all the dataframes, so we have all the data in one master_df."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaBxUQyUOPM9",
        "colab_type": "text"
      },
      "source": [
        "Merge All Files of Data Set \n",
        "# Merging the dataframes one by one\n",
        "df_1 = pd.merge(market_df, customer_df, how='inner', on='Cust_id')\n",
        "df_2 = pd.merge(df_1, product_df, how='inner', on='Prod_id')\n",
        "df_3 = pd.merge(df_2, shipping_df, how='inner', on='Ship_id')\n",
        "master_df = pd.merge(df_3, orders_df, how='inner', on='Ord_id')\n",
        "\n",
        "master_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF_tvt2COTDT",
        "colab_type": "text"
      },
      "source": [
        "Step 1. Grouping using df.groupby()\n",
        "Typically, you group the data using a categorical variable, such as customer segments, product categories, etc. This creates as many subsets of the data as there are levels in the categorical variable.\n",
        "\n",
        "For example, in this case, we will group the data along Customer_Segment.\n",
        "\n",
        "\n",
        "# Which customer segments are the least profitable? \n",
        "\n",
        "# Step 1. Grouping: First, we will group the dataframe by customer segments\n",
        "Syntax : df_by_segment = master_df.groupby('Customer_Segment') and \n",
        "df_by_segment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fDh2GyfOqtL",
        "colab_type": "text"
      },
      "source": [
        "Note that df.groupby returns a DataFrameGroupBy object.\n",
        "\n",
        "Step 2. Applying a Function\n",
        "After grouping, you apply a function to a numeric variable, such as mean(Sales), sum(Profit), etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajO7LUWrOxHQ",
        "colab_type": "text"
      },
      "source": [
        "Syntax : master_df[master_df['Customer_Segment']=='CORPORATE'][['Customer_Segment','Profit']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwhfazycO4gX",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06DZ34VuPBQp",
        "colab_type": "text"
      },
      "source": [
        "syntax : # Step 2. Applying a function\n",
        "# We can choose aggregate functions such as sum, mean, median, etc.\n",
        "df_by_segment['Profit'].sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bVFdVpRPG0B",
        "colab_type": "text"
      },
      "source": [
        "Syntax : # Alternatively\n",
        "df_by_segment.Profit.sum()\n",
        "  \n",
        "\n",
        "  # For better readability, you may want to sort the summarised series:\n",
        "df_by_segment.Profit.sum().sort_values(ascending = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3hQBzaePPI6",
        "colab_type": "text"
      },
      "source": [
        "Step 3. Combining the results into a Data Structure\n",
        "You can optionally show the results as a dataframe.\n",
        "\n",
        "\n",
        "syntax :   # Converting to a df\n",
        "rdf = pd.DataFrame(df_by_segment['Profit'].sum())  and rdf.reset_index() and # Let's go through some more examples\n",
        "# E.g.: Which product categories are the least profitable?\n",
        "\n",
        "# 1. Group by product category\n",
        "by_product_cat = master_df.groupby('Product_Category')   and # 2. This time, let's compare average profits\n",
        "# Apply mean() on Profit\n",
        "by_product_cat['Profit'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19f9cCSPPrqk",
        "colab_type": "text"
      },
      "source": [
        "FURNITURE is the least profitable, TECHNOLOGY the most. Let's see which product sub-cetgories within FURNITURE are less profitable.\n",
        "\n",
        "Syntax : # E.g.: Which product categories and sub-categories are the least profitable?\n",
        "# 1. Group by category and sub-category\n",
        "by_product_cat_subcat = master_df.groupby(['Product_Category', 'Product_Sub_Category'])\n",
        "by_product_cat_subcat['Profit'].mean()\n",
        "\n",
        "And\n",
        "\n",
        "ecall the df.describe() method?\n",
        "# To apply multiple functions simultaneously, you can use the describe() function on the grouped df object\n",
        "by_product_cat['Profit'].describe()# R\n",
        "\n",
        "\n",
        "and\n",
        "\n",
        "\n",
        "# Some other summary functions to apply on groups\n",
        "by_product_cat['Profit'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5nC5fV_QCQp",
        "colab_type": "text"
      },
      "source": [
        "by_product_cat['Profit'].min() \n",
        "\n",
        "and\n",
        "\n",
        "# E.g. Customers in which geographic region are the least profitable?\n",
        "master_df.groupby('Region').Profit.mean()\n",
        "\n",
        "and\n",
        "\n",
        "R1: 2/12*100\n",
        "R2: 2\n",
        "r3: 9\n",
        "\n",
        "\n",
        "# Note that the resulting object is a Series, thus you can perform vectorised computations on them\n",
        "\n",
        "# E.g. Calculate the Sales across each region as a percentage of total Sales\n",
        "# You can divide the entire series by a number (total sales) easily \n",
        "(master_df.groupby('Region').Sales.sum() / sum(master_df['Sales']))*100"
      ]
    }
  ]
}